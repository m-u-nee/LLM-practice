{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%inline` not found.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%inline matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n"
     ]
    }
   ],
   "source": [
    "#We used a (bad) model to generate a large list of names. now we will try to build a classifier to see if we can tell the difference between real and fake names.\n",
    "real_names = open('names.txt', 'r').read().splitlines()\n",
    "fake_names = open('generated_names.txt', 'r').read().splitlines()\n",
    "len(real_names), len(fake_names)\n",
    "#see if theere are names in both lists\n",
    "for name in real_names:\n",
    "    if name in fake_names:\n",
    "        print(name)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(real_names+fake_names))))\n",
    "stoi = {c:i+1 for i,c in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:c for c,i in stoi.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma................',\n",
       " 'olivia..............',\n",
       " 'ava.................',\n",
       " 'isabella............',\n",
       " 'sophia..............',\n",
       " 'charlotte...........',\n",
       " 'mia.................',\n",
       " 'amelia..............',\n",
       " 'harper..............',\n",
       " 'evelyn..............']"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find longest name\n",
    "maxlen = max([len(n) for n in real_names+fake_names])\n",
    "maxlen\n",
    "\n",
    "#pad all names to maxlen\n",
    "real_names = [n.ljust(maxlen, '.') for n in real_names]\n",
    "fake_names = [n.ljust(maxlen, '.') for n in fake_names]\n",
    "\n",
    "#print first 10 names\n",
    "real_names[:10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64066, 20])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Y's\n",
    "Y = torch.cat([torch.ones(len(real_names)), torch.zeros(len(fake_names))])\n",
    "Y.shape\n",
    "#add a dimension to Y\n",
    "Y = Y.unsqueeze(1)\n",
    "\n",
    "\n",
    "# create X's\n",
    "X = torch.cat([torch.LongTensor([[stoi[c] for c in n]]) for n in real_names+fake_names])\n",
    "X.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 24\n",
    "\n",
    "W1 = torch.randn(X.shape[1]*embedding_dim, 750, requires_grad=True)\n",
    "b1 = torch.randn(750, requires_grad=True)\n",
    "W2 = torch.randn(750, 1, requires_grad=True)\n",
    "b2 = torch.randn(1, requires_grad=True)\n",
    "\n",
    "C = torch.randn((27, embedding_dim), requires_grad=True)\n",
    "params = [W1, b1, W2, b2, C] \n",
    "\n",
    "\n",
    "def accuracy(pred, Y):\n",
    "    return (pred.round() == Y).float().mean()\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 8.288\n",
      "loss: 3.827\n",
      "loss: 2.888\n",
      "loss: 3.814\n",
      "loss: 2.999\n",
      "loss: 3.292\n",
      "loss: 1.690\n",
      "loss: 3.071\n",
      "loss: 2.188\n",
      "loss: 1.939\n",
      "loss: 2.356\n",
      "loss: 1.879\n",
      "loss: 1.663\n",
      "loss: 1.705\n",
      "loss: 2.179\n",
      "loss: 1.592\n",
      "loss: 1.150\n",
      "loss: 1.924\n",
      "loss: 2.189\n",
      "loss: 1.641\n",
      "loss: 1.466\n",
      "loss: 1.791\n",
      "loss: 1.515\n",
      "loss: 1.396\n",
      "loss: 1.490\n",
      "loss: 1.081\n",
      "loss: 1.332\n",
      "loss: 1.263\n",
      "loss: 1.138\n",
      "loss: 0.946\n",
      "loss: 1.321\n",
      "loss: 1.037\n",
      "loss: 1.063\n",
      "loss: 1.129\n",
      "loss: 1.429\n",
      "loss: 1.205\n",
      "loss: 1.069\n",
      "loss: 1.182\n",
      "loss: 0.595\n",
      "loss: 0.924\n",
      "loss: 1.002\n",
      "loss: 1.781\n",
      "loss: 1.281\n",
      "loss: 1.305\n",
      "loss: 1.165\n",
      "loss: 1.263\n",
      "loss: 1.077\n",
      "loss: 0.958\n",
      "loss: 0.874\n",
      "loss: 0.756\n",
      "loss: 0.985\n",
      "loss: 0.865\n",
      "loss: 1.270\n",
      "loss: 0.985\n",
      "loss: 0.941\n",
      "loss: 0.455\n",
      "loss: 0.712\n",
      "loss: 1.009\n",
      "loss: 0.730\n",
      "loss: 0.813\n",
      "loss: 0.775\n",
      "loss: 0.714\n",
      "loss: 0.615\n",
      "loss: 0.851\n",
      "loss: 0.636\n",
      "loss: 0.658\n",
      "loss: 1.030\n",
      "loss: 0.606\n",
      "loss: 0.735\n",
      "loss: 1.081\n",
      "loss: 0.859\n",
      "loss: 0.798\n",
      "loss: 0.691\n",
      "loss: 0.895\n",
      "loss: 0.672\n",
      "loss: 0.492\n",
      "loss: 1.092\n",
      "loss: 0.752\n",
      "loss: 0.684\n",
      "loss: 0.950\n",
      "loss: 0.867\n",
      "loss: 0.666\n",
      "loss: 0.504\n",
      "loss: 0.652\n",
      "loss: 0.633\n",
      "loss: 0.599\n",
      "loss: 0.831\n",
      "loss: 0.941\n",
      "loss: 0.695\n",
      "loss: 0.726\n",
      "loss: 0.795\n",
      "loss: 0.528\n",
      "loss: 0.915\n",
      "loss: 0.587\n",
      "loss: 0.612\n",
      "loss: 0.600\n",
      "loss: 0.514\n",
      "loss: 0.545\n",
      "loss: 0.628\n",
      "loss: 0.501\n",
      "loss: 0.667\n",
      "loss: 0.624\n",
      "loss: 0.615\n",
      "loss: 0.651\n",
      "loss: 0.488\n",
      "loss: 0.459\n",
      "loss: 0.828\n",
      "loss: 0.815\n",
      "loss: 0.541\n",
      "loss: 0.768\n",
      "loss: 0.615\n",
      "loss: 0.721\n",
      "loss: 0.674\n",
      "loss: 0.492\n",
      "loss: 0.681\n",
      "loss: 0.492\n",
      "loss: 0.560\n",
      "loss: 0.482\n",
      "loss: 0.793\n",
      "loss: 0.590\n",
      "loss: 0.515\n",
      "loss: 0.515\n",
      "loss: 0.457\n",
      "loss: 0.749\n",
      "loss: 0.540\n",
      "loss: 0.529\n",
      "loss: 0.593\n",
      "loss: 0.599\n",
      "loss: 0.491\n",
      "loss: 0.497\n",
      "loss: 0.559\n",
      "loss: 0.530\n",
      "loss: 0.946\n",
      "loss: 0.656\n",
      "loss: 0.664\n",
      "loss: 0.557\n",
      "loss: 0.589\n",
      "loss: 0.600\n",
      "loss: 0.507\n",
      "loss: 0.783\n",
      "loss: 0.440\n",
      "loss: 0.572\n",
      "loss: 0.605\n",
      "loss: 0.609\n",
      "loss: 0.521\n",
      "loss: 0.592\n",
      "loss: 0.669\n",
      "loss: 0.637\n",
      "loss: 0.519\n",
      "loss: 0.724\n",
      "loss: 0.524\n",
      "loss: 0.512\n",
      "loss: 0.701\n",
      "loss: 0.464\n",
      "loss: 0.532\n",
      "loss: 0.774\n",
      "loss: 0.611\n",
      "loss: 0.560\n",
      "loss: 0.506\n",
      "loss: 0.514\n",
      "loss: 0.507\n",
      "loss: 0.554\n",
      "loss: 0.599\n",
      "loss: 0.514\n",
      "loss: 0.572\n",
      "loss: 0.604\n",
      "loss: 0.800\n",
      "loss: 0.470\n",
      "loss: 0.534\n",
      "loss: 0.612\n",
      "loss: 0.555\n",
      "loss: 0.634\n",
      "loss: 0.625\n",
      "loss: 0.555\n",
      "loss: 0.474\n",
      "loss: 0.508\n",
      "loss: 0.503\n",
      "loss: 0.548\n",
      "loss: 0.553\n",
      "loss: 0.571\n",
      "loss: 0.514\n",
      "loss: 0.498\n",
      "loss: 0.642\n",
      "loss: 0.511\n",
      "loss: 0.626\n",
      "loss: 0.520\n",
      "loss: 0.643\n",
      "loss: 0.438\n",
      "loss: 0.589\n",
      "loss: 0.610\n",
      "loss: 0.542\n",
      "loss: 0.581\n",
      "loss: 0.463\n",
      "loss: 0.628\n",
      "loss: 0.759\n",
      "loss: 0.540\n",
      "loss: 0.708\n",
      "loss: 0.575\n",
      "loss: 0.577\n",
      "loss: 0.502\n",
      "loss: 0.567\n",
      "loss: 0.594\n",
      "loss: 0.612\n",
      "loss: 0.664\n",
      "loss: 0.432\n",
      "loss: 0.388\n",
      "loss: 0.533\n",
      "loss: 0.603\n",
      "loss: 0.530\n",
      "loss: 0.644\n",
      "loss: 0.415\n",
      "loss: 0.522\n",
      "loss: 0.682\n",
      "loss: 0.539\n",
      "loss: 0.674\n",
      "loss: 0.552\n",
      "loss: 0.574\n",
      "loss: 0.511\n",
      "loss: 0.591\n",
      "loss: 0.434\n",
      "loss: 0.504\n",
      "loss: 0.540\n",
      "loss: 0.420\n",
      "loss: 0.640\n",
      "loss: 0.417\n",
      "loss: 0.527\n",
      "loss: 0.558\n",
      "loss: 0.749\n",
      "loss: 0.601\n",
      "loss: 0.586\n",
      "loss: 0.426\n",
      "loss: 0.493\n",
      "loss: 0.595\n",
      "loss: 0.521\n",
      "loss: 0.571\n",
      "loss: 0.536\n",
      "loss: 0.621\n",
      "loss: 0.624\n",
      "loss: 0.484\n",
      "loss: 0.552\n",
      "loss: 0.410\n",
      "loss: 0.474\n",
      "loss: 0.546\n",
      "loss: 0.676\n",
      "loss: 0.552\n",
      "loss: 0.574\n",
      "loss: 0.520\n",
      "loss: 0.482\n",
      "loss: 0.590\n",
      "loss: 0.675\n",
      "loss: 0.628\n",
      "loss: 0.695\n",
      "loss: 0.425\n",
      "loss: 0.607\n",
      "loss: 0.613\n",
      "loss: 0.534\n",
      "loss: 0.533\n",
      "loss: 0.523\n",
      "loss: 0.497\n",
      "loss: 0.583\n",
      "loss: 0.582\n",
      "loss: 0.661\n",
      "loss: 0.462\n",
      "loss: 0.412\n",
      "loss: 0.422\n",
      "loss: 0.624\n",
      "loss: 0.428\n",
      "loss: 0.545\n",
      "loss: 0.532\n",
      "loss: 0.541\n",
      "loss: 0.541\n",
      "loss: 0.521\n",
      "loss: 0.559\n",
      "loss: 0.566\n",
      "loss: 0.572\n",
      "loss: 0.719\n",
      "loss: 0.428\n",
      "loss: 0.555\n",
      "loss: 0.586\n",
      "loss: 0.514\n",
      "loss: 0.629\n",
      "loss: 0.530\n",
      "loss: 0.689\n",
      "loss: 0.504\n",
      "loss: 0.598\n",
      "loss: 0.461\n",
      "loss: 0.615\n",
      "loss: 0.487\n",
      "loss: 0.419\n",
      "loss: 0.576\n",
      "loss: 0.610\n",
      "loss: 0.393\n",
      "loss: 0.741\n",
      "loss: 0.550\n",
      "loss: 0.611\n",
      "loss: 0.496\n",
      "loss: 0.535\n",
      "loss: 0.483\n",
      "loss: 0.632\n",
      "loss: 0.535\n",
      "loss: 0.542\n",
      "loss: 0.576\n",
      "loss: 0.595\n",
      "loss: 0.490\n",
      "loss: 0.506\n",
      "loss: 0.582\n",
      "loss: 0.420\n",
      "loss: 0.464\n",
      "loss: 0.567\n",
      "loss: 0.481\n",
      "loss: 0.529\n",
      "loss: 0.558\n",
      "loss: 0.644\n",
      "loss: 0.646\n",
      "loss: 0.578\n",
      "loss: 0.578\n",
      "loss: 0.614\n",
      "loss: 0.539\n",
      "loss: 0.500\n",
      "loss: 0.563\n",
      "loss: 0.535\n",
      "loss: 0.436\n",
      "loss: 0.526\n",
      "loss: 0.682\n",
      "loss: 0.570\n",
      "loss: 0.495\n",
      "loss: 0.635\n",
      "loss: 0.513\n",
      "loss: 0.416\n",
      "loss: 0.487\n",
      "loss: 0.385\n",
      "loss: 0.628\n",
      "loss: 0.616\n",
      "loss: 0.586\n",
      "loss: 0.508\n",
      "loss: 0.424\n",
      "loss: 0.486\n",
      "loss: 0.400\n",
      "loss: 0.459\n",
      "loss: 0.540\n",
      "loss: 0.555\n",
      "loss: 0.532\n",
      "loss: 0.532\n",
      "loss: 0.519\n",
      "loss: 0.523\n",
      "loss: 0.437\n",
      "loss: 0.501\n",
      "loss: 0.430\n",
      "loss: 0.533\n",
      "loss: 0.586\n",
      "loss: 0.513\n",
      "loss: 0.454\n",
      "loss: 0.463\n",
      "loss: 0.491\n",
      "loss: 0.529\n",
      "loss: 0.463\n",
      "loss: 0.391\n",
      "loss: 0.592\n",
      "loss: 0.608\n",
      "loss: 0.492\n",
      "loss: 0.596\n",
      "loss: 0.439\n",
      "loss: 0.571\n",
      "loss: 0.432\n",
      "loss: 0.540\n",
      "loss: 0.529\n",
      "loss: 0.509\n",
      "loss: 0.547\n",
      "loss: 0.471\n",
      "loss: 0.627\n",
      "loss: 0.543\n",
      "loss: 0.481\n",
      "loss: 0.625\n",
      "loss: 0.549\n",
      "loss: 0.460\n",
      "loss: 0.598\n",
      "loss: 0.474\n",
      "loss: 0.481\n",
      "loss: 0.462\n",
      "loss: 0.501\n",
      "loss: 0.459\n",
      "loss: 0.559\n",
      "loss: 0.514\n",
      "loss: 0.485\n",
      "loss: 0.551\n",
      "loss: 0.478\n",
      "loss: 0.584\n",
      "loss: 0.484\n",
      "loss: 0.566\n",
      "loss: 0.400\n",
      "loss: 0.474\n",
      "loss: 0.546\n",
      "loss: 0.570\n",
      "loss: 0.636\n",
      "loss: 0.439\n",
      "loss: 0.428\n",
      "loss: 0.577\n",
      "loss: 0.486\n",
      "loss: 0.676\n",
      "loss: 0.431\n",
      "loss: 0.540\n",
      "loss: 0.616\n",
      "loss: 0.449\n",
      "loss: 0.695\n",
      "loss: 0.520\n",
      "loss: 0.631\n",
      "loss: 0.512\n",
      "loss: 0.599\n",
      "loss: 0.633\n",
      "loss: 0.503\n",
      "loss: 0.559\n",
      "loss: 0.555\n",
      "loss: 0.448\n",
      "loss: 0.499\n",
      "loss: 0.497\n",
      "loss: 0.656\n",
      "loss: 0.584\n",
      "loss: 0.443\n",
      "loss: 0.534\n",
      "loss: 0.474\n",
      "loss: 0.496\n",
      "loss: 0.492\n",
      "loss: 0.390\n",
      "loss: 0.549\n",
      "loss: 0.509\n",
      "loss: 0.519\n",
      "loss: 0.431\n",
      "loss: 0.566\n",
      "loss: 0.512\n",
      "loss: 0.472\n",
      "loss: 0.514\n",
      "loss: 0.482\n",
      "loss: 0.528\n",
      "loss: 0.637\n",
      "loss: 0.543\n",
      "loss: 0.578\n",
      "loss: 0.541\n",
      "loss: 0.448\n",
      "loss: 0.554\n",
      "loss: 0.743\n",
      "loss: 0.614\n",
      "loss: 0.509\n",
      "loss: 0.461\n",
      "loss: 0.648\n",
      "loss: 0.437\n",
      "loss: 0.465\n",
      "loss: 0.441\n",
      "loss: 0.539\n",
      "loss: 0.455\n",
      "loss: 0.615\n",
      "loss: 0.468\n",
      "loss: 0.440\n",
      "loss: 0.534\n",
      "loss: 0.594\n",
      "loss: 0.452\n",
      "loss: 0.563\n",
      "loss: 0.497\n",
      "loss: 0.454\n",
      "loss: 0.536\n",
      "loss: 0.400\n",
      "loss: 0.537\n",
      "loss: 0.479\n",
      "loss: 0.418\n",
      "loss: 0.424\n",
      "loss: 0.502\n",
      "loss: 0.370\n",
      "loss: 0.518\n",
      "loss: 0.512\n",
      "loss: 0.542\n",
      "loss: 0.443\n",
      "loss: 0.686\n",
      "loss: 0.427\n",
      "loss: 0.432\n",
      "loss: 0.544\n",
      "loss: 0.462\n",
      "loss: 0.628\n",
      "loss: 0.459\n",
      "loss: 0.646\n",
      "loss: 0.549\n",
      "loss: 0.576\n",
      "loss: 0.426\n",
      "loss: 0.528\n",
      "loss: 0.467\n",
      "loss: 0.502\n",
      "loss: 0.730\n",
      "loss: 0.505\n",
      "loss: 0.461\n",
      "loss: 0.469\n",
      "loss: 0.544\n",
      "loss: 0.575\n",
      "loss: 0.588\n",
      "loss: 0.370\n",
      "loss: 0.641\n",
      "loss: 0.540\n",
      "loss: 0.507\n",
      "loss: 0.725\n",
      "loss: 0.471\n",
      "loss: 0.601\n",
      "loss: 0.561\n",
      "loss: 0.455\n",
      "loss: 0.502\n",
      "loss: 0.452\n",
      "loss: 0.556\n",
      "loss: 0.454\n",
      "loss: 0.599\n",
      "loss: 0.461\n",
      "loss: 0.503\n",
      "loss: 0.495\n",
      "loss: 0.580\n",
      "loss: 0.673\n",
      "loss: 0.575\n",
      "loss: 0.470\n",
      "loss: 0.514\n",
      "loss: 0.510\n",
      "loss: 0.470\n",
      "loss: 0.572\n",
      "loss: 0.475\n",
      "loss: 0.412\n",
      "loss: 0.397\n",
      "loss: 0.548\n",
      "loss: 0.349\n",
      "loss: 0.489\n",
      "loss: 0.468\n",
      "loss: 0.570\n",
      "loss: 0.628\n",
      "loss: 0.582\n",
      "loss: 0.559\n",
      "loss: 0.410\n",
      "loss: 0.409\n",
      "loss: 0.450\n",
      "loss: 0.604\n",
      "loss: 0.462\n",
      "loss: 0.596\n",
      "loss: 0.507\n",
      "loss: 0.584\n",
      "loss: 0.471\n",
      "loss: 0.442\n",
      "loss: 0.474\n",
      "loss: 0.556\n",
      "loss: 0.456\n",
      "loss: 0.521\n",
      "loss: 0.499\n",
      "loss: 0.545\n",
      "loss: 0.557\n",
      "loss: 0.558\n",
      "loss: 0.414\n",
      "loss: 0.480\n",
      "loss: 0.371\n",
      "loss: 0.598\n",
      "loss: 0.554\n",
      "loss: 0.521\n",
      "loss: 0.408\n",
      "loss: 0.521\n",
      "loss: 0.439\n",
      "loss: 0.460\n",
      "loss: 0.483\n",
      "loss: 0.449\n",
      "loss: 0.491\n",
      "loss: 0.494\n",
      "loss: 0.511\n",
      "loss: 0.516\n",
      "loss: 0.503\n",
      "loss: 0.741\n",
      "loss: 0.397\n",
      "loss: 0.428\n",
      "loss: 0.530\n",
      "loss: 0.452\n",
      "loss: 0.558\n",
      "loss: 0.469\n",
      "loss: 0.581\n",
      "loss: 0.542\n",
      "loss: 0.399\n",
      "loss: 0.598\n",
      "loss: 0.549\n",
      "loss: 0.463\n",
      "loss: 0.368\n",
      "loss: 0.519\n",
      "loss: 0.608\n",
      "loss: 0.546\n",
      "loss: 0.485\n",
      "loss: 0.507\n",
      "loss: 0.428\n",
      "loss: 0.505\n",
      "loss: 0.492\n",
      "loss: 0.542\n",
      "loss: 0.473\n",
      "loss: 0.428\n",
      "loss: 0.531\n",
      "loss: 0.530\n",
      "loss: 0.501\n",
      "loss: 0.519\n",
      "loss: 0.496\n",
      "loss: 0.455\n",
      "loss: 0.467\n",
      "loss: 0.526\n",
      "loss: 0.569\n",
      "loss: 0.626\n",
      "loss: 0.401\n",
      "loss: 0.396\n",
      "loss: 0.432\n",
      "loss: 0.605\n",
      "loss: 0.413\n",
      "loss: 0.451\n",
      "loss: 0.527\n",
      "loss: 0.558\n",
      "loss: 0.544\n",
      "loss: 0.733\n",
      "loss: 0.524\n",
      "loss: 0.382\n",
      "loss: 0.491\n",
      "loss: 0.481\n",
      "loss: 0.459\n",
      "loss: 0.503\n",
      "loss: 0.489\n",
      "loss: 0.444\n",
      "loss: 0.444\n",
      "loss: 0.502\n",
      "loss: 0.646\n",
      "loss: 0.594\n",
      "loss: 0.489\n",
      "loss: 0.495\n",
      "loss: 0.447\n",
      "loss: 0.633\n",
      "loss: 0.488\n",
      "loss: 0.520\n",
      "loss: 0.435\n",
      "loss: 0.452\n",
      "loss: 0.506\n",
      "loss: 0.448\n",
      "loss: 0.396\n",
      "loss: 0.631\n",
      "loss: 0.592\n",
      "loss: 0.428\n",
      "loss: 0.482\n",
      "loss: 0.446\n",
      "loss: 0.496\n",
      "loss: 0.541\n",
      "loss: 0.384\n",
      "loss: 0.474\n",
      "loss: 0.453\n",
      "loss: 0.513\n",
      "loss: 0.621\n",
      "loss: 0.464\n",
      "loss: 0.444\n",
      "loss: 0.478\n",
      "loss: 0.526\n",
      "loss: 0.492\n",
      "loss: 0.497\n",
      "loss: 0.544\n",
      "loss: 0.557\n",
      "loss: 0.541\n",
      "loss: 0.457\n",
      "loss: 0.635\n",
      "loss: 0.543\n",
      "loss: 0.535\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "for i in range(100000):\n",
    "    ix = torch.randint(0, X.shape[0], (batch_size,))\n",
    "    emb = C[X[ix]]\n",
    "    h = torch.tanh(emb.view(-1, 20*embedding_dim) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    #we use binary cross entropy loss because we are doing binary classification\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, Y[ix])\n",
    "    loss.backward()\n",
    "    acc = accuracy(logits, Y[ix])\n",
    "    for p in params:\n",
    "        p.data -= p.grad * lr\n",
    "        p.grad.zero_()\n",
    "    if i % 100 == 0:\n",
    "        print(f'loss: {loss.data:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7734)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy on whole dataset\n",
    "pred = torch.sigmoid((torch.tanh(C[X].view(-1, 20*embedding_dim) @ W1 + b1) @ W2 + b2))\n",
    "accuracy(pred, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
