{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We complexify the previoius model\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle up the words\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 16]) torch.Size([182625])\n",
      "torch.Size([22655, 16]) torch.Size([22655])\n",
      "torch.Size([22866, 16]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 16 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]  # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "Xtr,  Ytr = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near copy paste of the layers we have developed in Part 3\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Linear:\n",
    "\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out)) / \\\n",
    "            fan_in**0.5  # note: kaiming init\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # buffers (trained with a running 'momentum update')\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        if self.training:\n",
    "            if x.ndim == 2:\n",
    "                dim = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0, 1)\n",
    "            xmean = x.mean(dim, keepdim=True)  # batch mean\n",
    "            xvar = x.var(dim, keepdim=True)  # batch variance\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        # normalize to unit variance\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update the buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * \\\n",
    "                    self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * \\\n",
    "                    self.running_var + self.momentum * xvar\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "class Embedding:\n",
    "\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim)) \n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = self.weight[x]\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "    \n",
    "class FlattenConsecutive:\n",
    "    def __init__(self, n ):\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T//self.n , C*self.n)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "class Sequential:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13594\n"
     ]
    }
   ],
   "source": [
    "n_embd = 12\n",
    "n_hidden = 32\n",
    "\n",
    "\n",
    "\n",
    "layers = [\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(2),\n",
    "    Linear(n_embd * 2, n_hidden, bias=False),\n",
    "    BatchNorm1d(n_hidden),\n",
    "    Tanh(),\n",
    "    FlattenConsecutive(2),\n",
    "    Linear(n_hidden * 2, n_hidden, bias = False),\n",
    "    BatchNorm1d(n_hidden),\n",
    "    Tanh(),\n",
    "    FlattenConsecutive(2),\n",
    "    Linear(n_hidden * 2, n_hidden, bias = False),\n",
    "    BatchNorm1d(n_hidden),\n",
    "    Tanh(),\n",
    "    FlattenConsecutive(2),\n",
    "    Linear(n_hidden * 2, n_hidden, bias = False),\n",
    "    BatchNorm1d(n_hidden),\n",
    "    Tanh(),\n",
    "    Linear(n_hidden, vocab_size) \n",
    "]\n",
    "model = Sequential(layers)\n",
    "skip_layer = Linear(n_embd * block_size, vocab_size, bias=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    layers[-1].weight *= 0.1  # make less confident\n",
    "    skip_layer.weight *= 0.1  # make less confident\n",
    "\n",
    "parameters = [p for l in layers for p in l.parameters()] + [skip_layer.weight, skip_layer.bias]\n",
    "print(sum(p.numel() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.1, Iteration number: 0/300000, Loss: 2.2367\n",
      "Learning rate: 0.1, Iteration number: 1000/300000, Loss: 2.2405\n",
      "Learning rate: 0.1, Iteration number: 2000/300000, Loss: 2.1059\n",
      "Learning rate: 0.1, Iteration number: 3000/300000, Loss: 2.1802\n",
      "Learning rate: 0.1, Iteration number: 4000/300000, Loss: 2.2141\n",
      "Learning rate: 0.1, Iteration number: 5000/300000, Loss: 2.1177\n",
      "Learning rate: 0.1, Iteration number: 6000/300000, Loss: 1.9876\n",
      "Learning rate: 0.1, Iteration number: 7000/300000, Loss: 1.9972\n",
      "Learning rate: 0.1, Iteration number: 8000/300000, Loss: 2.0962\n",
      "Learning rate: 0.1, Iteration number: 9000/300000, Loss: 2.0699\n",
      "Learning rate: 0.1, Iteration number: 10000/300000, Loss: 2.0775\n",
      "Learning rate: 0.1, Iteration number: 11000/300000, Loss: 2.2604\n",
      "Learning rate: 0.1, Iteration number: 12000/300000, Loss: 1.8376\n",
      "Learning rate: 0.1, Iteration number: 13000/300000, Loss: 2.1690\n",
      "Learning rate: 0.1, Iteration number: 14000/300000, Loss: 2.1011\n",
      "Learning rate: 0.1, Iteration number: 15000/300000, Loss: 2.1008\n",
      "Learning rate: 0.1, Iteration number: 16000/300000, Loss: 2.0881\n",
      "Learning rate: 0.1, Iteration number: 17000/300000, Loss: 2.1539\n",
      "Learning rate: 0.1, Iteration number: 18000/300000, Loss: 1.9217\n",
      "Learning rate: 0.1, Iteration number: 19000/300000, Loss: 2.1383\n",
      "Learning rate: 0.1, Iteration number: 20000/300000, Loss: 2.2077\n",
      "Learning rate: 0.1, Iteration number: 21000/300000, Loss: 1.9402\n",
      "Learning rate: 0.1, Iteration number: 22000/300000, Loss: 2.1715\n",
      "Learning rate: 0.1, Iteration number: 23000/300000, Loss: 1.9967\n",
      "Learning rate: 0.1, Iteration number: 24000/300000, Loss: 2.1828\n",
      "Learning rate: 0.1, Iteration number: 25000/300000, Loss: 2.0484\n",
      "Learning rate: 0.1, Iteration number: 26000/300000, Loss: 2.1696\n",
      "Learning rate: 0.1, Iteration number: 27000/300000, Loss: 2.2071\n",
      "Learning rate: 0.1, Iteration number: 28000/300000, Loss: 2.0707\n",
      "Learning rate: 0.1, Iteration number: 29000/300000, Loss: 2.0472\n",
      "Learning rate: 0.1, Iteration number: 30000/300000, Loss: 1.9402\n",
      "Learning rate: 0.1, Iteration number: 31000/300000, Loss: 1.9949\n",
      "Learning rate: 0.1, Iteration number: 32000/300000, Loss: 2.1597\n",
      "Learning rate: 0.1, Iteration number: 33000/300000, Loss: 2.0488\n",
      "Learning rate: 0.1, Iteration number: 34000/300000, Loss: 2.0772\n",
      "Learning rate: 0.1, Iteration number: 35000/300000, Loss: 2.0061\n",
      "Learning rate: 0.1, Iteration number: 36000/300000, Loss: 2.2856\n",
      "Learning rate: 0.1, Iteration number: 37000/300000, Loss: 2.1459\n",
      "Learning rate: 0.1, Iteration number: 38000/300000, Loss: 1.8418\n",
      "Learning rate: 0.1, Iteration number: 39000/300000, Loss: 2.1283\n",
      "Learning rate: 0.1, Iteration number: 40000/300000, Loss: 1.8314\n",
      "Learning rate: 0.1, Iteration number: 41000/300000, Loss: 2.0462\n",
      "Learning rate: 0.1, Iteration number: 42000/300000, Loss: 2.0226\n",
      "Learning rate: 0.1, Iteration number: 43000/300000, Loss: 2.0066\n",
      "Learning rate: 0.1, Iteration number: 44000/300000, Loss: 1.9863\n",
      "Learning rate: 0.1, Iteration number: 45000/300000, Loss: 2.0446\n",
      "Learning rate: 0.1, Iteration number: 46000/300000, Loss: 1.9791\n",
      "Learning rate: 0.1, Iteration number: 47000/300000, Loss: 2.0738\n",
      "Learning rate: 0.1, Iteration number: 48000/300000, Loss: 2.0208\n",
      "Learning rate: 0.1, Iteration number: 49000/300000, Loss: 2.0376\n",
      "Learning rate: 0.1, Iteration number: 50000/300000, Loss: 2.0206\n",
      "Learning rate: 0.1, Iteration number: 51000/300000, Loss: 2.0263\n",
      "Learning rate: 0.1, Iteration number: 52000/300000, Loss: 1.9136\n",
      "Learning rate: 0.1, Iteration number: 53000/300000, Loss: 1.9315\n",
      "Learning rate: 0.1, Iteration number: 54000/300000, Loss: 1.9971\n",
      "Learning rate: 0.1, Iteration number: 55000/300000, Loss: 2.1017\n",
      "Learning rate: 0.1, Iteration number: 56000/300000, Loss: 2.0727\n",
      "Learning rate: 0.1, Iteration number: 57000/300000, Loss: 1.9629\n",
      "Learning rate: 0.1, Iteration number: 58000/300000, Loss: 1.9289\n",
      "Learning rate: 0.1, Iteration number: 59000/300000, Loss: 2.1526\n",
      "Learning rate: 0.1, Iteration number: 60000/300000, Loss: 2.2567\n",
      "Learning rate: 0.1, Iteration number: 61000/300000, Loss: 2.1707\n",
      "Learning rate: 0.1, Iteration number: 62000/300000, Loss: 1.9383\n",
      "Learning rate: 0.1, Iteration number: 63000/300000, Loss: 2.0686\n",
      "Learning rate: 0.1, Iteration number: 64000/300000, Loss: 2.0793\n",
      "Learning rate: 0.1, Iteration number: 65000/300000, Loss: 2.0107\n",
      "Learning rate: 0.1, Iteration number: 66000/300000, Loss: 1.8699\n",
      "Learning rate: 0.1, Iteration number: 67000/300000, Loss: 2.1775\n",
      "Learning rate: 0.1, Iteration number: 68000/300000, Loss: 2.0430\n",
      "Learning rate: 0.1, Iteration number: 69000/300000, Loss: 2.0571\n",
      "Learning rate: 0.1, Iteration number: 70000/300000, Loss: 1.7992\n",
      "Learning rate: 0.1, Iteration number: 71000/300000, Loss: 2.1870\n",
      "Learning rate: 0.1, Iteration number: 72000/300000, Loss: 1.8973\n",
      "Learning rate: 0.1, Iteration number: 73000/300000, Loss: 1.8514\n",
      "Learning rate: 0.1, Iteration number: 74000/300000, Loss: 2.0337\n",
      "Learning rate: 0.1, Iteration number: 75000/300000, Loss: 2.1506\n",
      "Learning rate: 0.1, Iteration number: 76000/300000, Loss: 1.9883\n",
      "Learning rate: 0.1, Iteration number: 77000/300000, Loss: 1.9382\n",
      "Learning rate: 0.1, Iteration number: 78000/300000, Loss: 2.0592\n",
      "Learning rate: 0.1, Iteration number: 79000/300000, Loss: 1.8227\n",
      "Learning rate: 0.1, Iteration number: 80000/300000, Loss: 2.0154\n",
      "Learning rate: 0.1, Iteration number: 81000/300000, Loss: 2.0858\n",
      "Learning rate: 0.1, Iteration number: 82000/300000, Loss: 1.9657\n",
      "Learning rate: 0.1, Iteration number: 83000/300000, Loss: 2.1869\n",
      "Learning rate: 0.1, Iteration number: 84000/300000, Loss: 1.9822\n",
      "Learning rate: 0.1, Iteration number: 85000/300000, Loss: 2.0499\n",
      "Learning rate: 0.1, Iteration number: 86000/300000, Loss: 2.0817\n",
      "Learning rate: 0.1, Iteration number: 87000/300000, Loss: 1.9936\n",
      "Learning rate: 0.1, Iteration number: 88000/300000, Loss: 2.1038\n",
      "Learning rate: 0.1, Iteration number: 89000/300000, Loss: 2.1287\n",
      "Learning rate: 0.1, Iteration number: 90000/300000, Loss: 2.0569\n",
      "Learning rate: 0.1, Iteration number: 91000/300000, Loss: 1.9321\n",
      "Learning rate: 0.1, Iteration number: 92000/300000, Loss: 2.2765\n",
      "Learning rate: 0.1, Iteration number: 93000/300000, Loss: 1.9502\n",
      "Learning rate: 0.1, Iteration number: 94000/300000, Loss: 2.1796\n",
      "Learning rate: 0.1, Iteration number: 95000/300000, Loss: 1.9106\n",
      "Learning rate: 0.1, Iteration number: 96000/300000, Loss: 2.2806\n",
      "Learning rate: 0.1, Iteration number: 97000/300000, Loss: 2.0707\n",
      "Learning rate: 0.1, Iteration number: 98000/300000, Loss: 1.9050\n",
      "Learning rate: 0.1, Iteration number: 99000/300000, Loss: 1.9043\n",
      "Learning rate: 0.1, Iteration number: 99999/300000, Loss: 2.1022\n",
      "Learning rate: 0.01, Iteration number: 100000/300000, Loss: 2.1019\n",
      "Learning rate: 0.01, Iteration number: 101000/300000, Loss: 2.0761\n",
      "Learning rate: 0.01, Iteration number: 102000/300000, Loss: 2.0429\n",
      "Learning rate: 0.01, Iteration number: 103000/300000, Loss: 1.9890\n",
      "Learning rate: 0.01, Iteration number: 104000/300000, Loss: 1.8145\n",
      "Learning rate: 0.01, Iteration number: 105000/300000, Loss: 1.9822\n",
      "Learning rate: 0.01, Iteration number: 106000/300000, Loss: 2.2472\n",
      "Learning rate: 0.01, Iteration number: 107000/300000, Loss: 1.8938\n",
      "Learning rate: 0.01, Iteration number: 108000/300000, Loss: 1.9632\n",
      "Learning rate: 0.01, Iteration number: 109000/300000, Loss: 1.9465\n",
      "Learning rate: 0.01, Iteration number: 110000/300000, Loss: 1.8902\n",
      "Learning rate: 0.01, Iteration number: 111000/300000, Loss: 1.8790\n",
      "Learning rate: 0.01, Iteration number: 112000/300000, Loss: 2.1710\n",
      "Learning rate: 0.01, Iteration number: 113000/300000, Loss: 2.0955\n",
      "Learning rate: 0.01, Iteration number: 114000/300000, Loss: 1.8730\n",
      "Learning rate: 0.01, Iteration number: 115000/300000, Loss: 1.8506\n",
      "Learning rate: 0.01, Iteration number: 116000/300000, Loss: 2.1189\n",
      "Learning rate: 0.01, Iteration number: 117000/300000, Loss: 2.1020\n",
      "Learning rate: 0.01, Iteration number: 118000/300000, Loss: 2.0413\n",
      "Learning rate: 0.01, Iteration number: 119000/300000, Loss: 1.8745\n",
      "Learning rate: 0.01, Iteration number: 120000/300000, Loss: 1.9298\n",
      "Learning rate: 0.01, Iteration number: 121000/300000, Loss: 2.0327\n",
      "Learning rate: 0.01, Iteration number: 122000/300000, Loss: 1.9822\n",
      "Learning rate: 0.01, Iteration number: 123000/300000, Loss: 2.1415\n",
      "Learning rate: 0.01, Iteration number: 124000/300000, Loss: 2.0167\n",
      "Learning rate: 0.01, Iteration number: 125000/300000, Loss: 1.7786\n",
      "Learning rate: 0.01, Iteration number: 126000/300000, Loss: 2.0565\n",
      "Learning rate: 0.01, Iteration number: 127000/300000, Loss: 2.1900\n",
      "Learning rate: 0.01, Iteration number: 128000/300000, Loss: 1.9803\n",
      "Learning rate: 0.01, Iteration number: 129000/300000, Loss: 2.0596\n",
      "Learning rate: 0.01, Iteration number: 130000/300000, Loss: 1.8534\n",
      "Learning rate: 0.01, Iteration number: 131000/300000, Loss: 2.0238\n",
      "Learning rate: 0.01, Iteration number: 132000/300000, Loss: 2.0496\n",
      "Learning rate: 0.01, Iteration number: 133000/300000, Loss: 2.0659\n",
      "Learning rate: 0.01, Iteration number: 134000/300000, Loss: 1.7907\n",
      "Learning rate: 0.01, Iteration number: 135000/300000, Loss: 2.0128\n",
      "Learning rate: 0.01, Iteration number: 136000/300000, Loss: 1.9659\n",
      "Learning rate: 0.01, Iteration number: 137000/300000, Loss: 1.9949\n",
      "Learning rate: 0.01, Iteration number: 138000/300000, Loss: 1.9800\n",
      "Learning rate: 0.01, Iteration number: 139000/300000, Loss: 2.0676\n",
      "Learning rate: 0.01, Iteration number: 140000/300000, Loss: 1.8807\n",
      "Learning rate: 0.01, Iteration number: 141000/300000, Loss: 1.8924\n",
      "Learning rate: 0.01, Iteration number: 142000/300000, Loss: 2.0315\n",
      "Learning rate: 0.01, Iteration number: 143000/300000, Loss: 2.0085\n",
      "Learning rate: 0.01, Iteration number: 144000/300000, Loss: 2.2316\n",
      "Learning rate: 0.01, Iteration number: 145000/300000, Loss: 1.9404\n",
      "Learning rate: 0.01, Iteration number: 146000/300000, Loss: 1.9194\n",
      "Learning rate: 0.01, Iteration number: 147000/300000, Loss: 1.9646\n",
      "Learning rate: 0.01, Iteration number: 148000/300000, Loss: 2.0232\n",
      "Learning rate: 0.01, Iteration number: 149000/300000, Loss: 2.0143\n",
      "Learning rate: 0.01, Iteration number: 150000/300000, Loss: 1.8563\n",
      "Learning rate: 0.01, Iteration number: 151000/300000, Loss: 1.9690\n",
      "Learning rate: 0.01, Iteration number: 152000/300000, Loss: 1.8456\n",
      "Learning rate: 0.01, Iteration number: 153000/300000, Loss: 2.0662\n",
      "Learning rate: 0.01, Iteration number: 154000/300000, Loss: 1.9189\n",
      "Learning rate: 0.01, Iteration number: 155000/300000, Loss: 1.8572\n",
      "Learning rate: 0.01, Iteration number: 156000/300000, Loss: 1.8856\n",
      "Learning rate: 0.01, Iteration number: 157000/300000, Loss: 1.9052\n",
      "Learning rate: 0.01, Iteration number: 158000/300000, Loss: 2.1252\n",
      "Learning rate: 0.01, Iteration number: 159000/300000, Loss: 1.8743\n",
      "Learning rate: 0.01, Iteration number: 160000/300000, Loss: 1.8580\n",
      "Learning rate: 0.01, Iteration number: 161000/300000, Loss: 1.9406\n",
      "Learning rate: 0.01, Iteration number: 162000/300000, Loss: 1.9784\n",
      "Learning rate: 0.01, Iteration number: 163000/300000, Loss: 2.1133\n",
      "Learning rate: 0.01, Iteration number: 164000/300000, Loss: 1.8336\n",
      "Learning rate: 0.01, Iteration number: 165000/300000, Loss: 1.8837\n",
      "Learning rate: 0.01, Iteration number: 166000/300000, Loss: 2.1862\n",
      "Learning rate: 0.01, Iteration number: 167000/300000, Loss: 2.2181\n",
      "Learning rate: 0.01, Iteration number: 168000/300000, Loss: 1.9579\n",
      "Learning rate: 0.01, Iteration number: 169000/300000, Loss: 1.9736\n",
      "Learning rate: 0.01, Iteration number: 170000/300000, Loss: 2.0612\n",
      "Learning rate: 0.01, Iteration number: 171000/300000, Loss: 2.0068\n",
      "Learning rate: 0.01, Iteration number: 172000/300000, Loss: 1.8635\n",
      "Learning rate: 0.01, Iteration number: 173000/300000, Loss: 1.8722\n",
      "Learning rate: 0.01, Iteration number: 174000/300000, Loss: 2.0462\n",
      "Learning rate: 0.01, Iteration number: 175000/300000, Loss: 2.0159\n",
      "Learning rate: 0.01, Iteration number: 176000/300000, Loss: 1.9730\n",
      "Learning rate: 0.01, Iteration number: 177000/300000, Loss: 1.9504\n",
      "Learning rate: 0.01, Iteration number: 178000/300000, Loss: 2.1235\n",
      "Learning rate: 0.01, Iteration number: 179000/300000, Loss: 1.9657\n",
      "Learning rate: 0.01, Iteration number: 180000/300000, Loss: 1.9944\n",
      "Learning rate: 0.01, Iteration number: 181000/300000, Loss: 2.0829\n",
      "Learning rate: 0.01, Iteration number: 182000/300000, Loss: 1.9187\n",
      "Learning rate: 0.01, Iteration number: 183000/300000, Loss: 2.0379\n",
      "Learning rate: 0.01, Iteration number: 184000/300000, Loss: 1.8759\n",
      "Learning rate: 0.01, Iteration number: 185000/300000, Loss: 1.9765\n",
      "Learning rate: 0.01, Iteration number: 186000/300000, Loss: 1.8971\n",
      "Learning rate: 0.01, Iteration number: 187000/300000, Loss: 2.0071\n",
      "Learning rate: 0.01, Iteration number: 188000/300000, Loss: 1.9846\n",
      "Learning rate: 0.01, Iteration number: 189000/300000, Loss: 1.8915\n",
      "Learning rate: 0.01, Iteration number: 190000/300000, Loss: 1.8362\n",
      "Learning rate: 0.01, Iteration number: 191000/300000, Loss: 2.0481\n",
      "Learning rate: 0.01, Iteration number: 192000/300000, Loss: 2.2101\n",
      "Learning rate: 0.01, Iteration number: 193000/300000, Loss: 2.1245\n",
      "Learning rate: 0.01, Iteration number: 194000/300000, Loss: 2.0235\n",
      "Learning rate: 0.01, Iteration number: 195000/300000, Loss: 1.9910\n",
      "Learning rate: 0.01, Iteration number: 196000/300000, Loss: 1.8732\n",
      "Learning rate: 0.01, Iteration number: 197000/300000, Loss: 2.0312\n",
      "Learning rate: 0.01, Iteration number: 198000/300000, Loss: 2.1393\n",
      "Learning rate: 0.01, Iteration number: 199000/300000, Loss: 1.9897\n",
      "Learning rate: 0.01, Iteration number: 199999/300000, Loss: 1.8678\n",
      "Learning rate: 0.005, Iteration number: 200000/300000, Loss: 2.0317\n",
      "Learning rate: 0.005, Iteration number: 201000/300000, Loss: 2.1273\n",
      "Learning rate: 0.005, Iteration number: 202000/300000, Loss: 1.9903\n",
      "Learning rate: 0.005, Iteration number: 203000/300000, Loss: 2.1008\n",
      "Learning rate: 0.005, Iteration number: 204000/300000, Loss: 1.8251\n",
      "Learning rate: 0.005, Iteration number: 205000/300000, Loss: 2.1383\n",
      "Learning rate: 0.005, Iteration number: 206000/300000, Loss: 1.9636\n",
      "Learning rate: 0.005, Iteration number: 207000/300000, Loss: 1.9059\n",
      "Learning rate: 0.005, Iteration number: 208000/300000, Loss: 2.0283\n",
      "Learning rate: 0.005, Iteration number: 209000/300000, Loss: 2.2175\n",
      "Learning rate: 0.005, Iteration number: 210000/300000, Loss: 2.0656\n",
      "Learning rate: 0.005, Iteration number: 211000/300000, Loss: 1.9132\n",
      "Learning rate: 0.005, Iteration number: 212000/300000, Loss: 1.7046\n",
      "Learning rate: 0.005, Iteration number: 213000/300000, Loss: 1.8568\n",
      "Learning rate: 0.005, Iteration number: 214000/300000, Loss: 2.0223\n",
      "Learning rate: 0.005, Iteration number: 215000/300000, Loss: 1.9612\n",
      "Learning rate: 0.005, Iteration number: 216000/300000, Loss: 1.8197\n",
      "Learning rate: 0.005, Iteration number: 217000/300000, Loss: 1.9677\n",
      "Learning rate: 0.005, Iteration number: 218000/300000, Loss: 2.0812\n",
      "Learning rate: 0.005, Iteration number: 219000/300000, Loss: 1.9322\n",
      "Learning rate: 0.005, Iteration number: 220000/300000, Loss: 2.0358\n",
      "Learning rate: 0.005, Iteration number: 221000/300000, Loss: 1.9125\n",
      "Learning rate: 0.005, Iteration number: 222000/300000, Loss: 2.1815\n",
      "Learning rate: 0.005, Iteration number: 223000/300000, Loss: 2.0475\n",
      "Learning rate: 0.005, Iteration number: 224000/300000, Loss: 1.8841\n",
      "Learning rate: 0.005, Iteration number: 225000/300000, Loss: 1.8213\n",
      "Learning rate: 0.005, Iteration number: 226000/300000, Loss: 2.0329\n",
      "Learning rate: 0.005, Iteration number: 227000/300000, Loss: 1.8880\n",
      "Learning rate: 0.005, Iteration number: 228000/300000, Loss: 1.6908\n",
      "Learning rate: 0.005, Iteration number: 229000/300000, Loss: 1.8361\n",
      "Learning rate: 0.005, Iteration number: 230000/300000, Loss: 2.0592\n",
      "Learning rate: 0.005, Iteration number: 231000/300000, Loss: 2.1691\n",
      "Learning rate: 0.005, Iteration number: 232000/300000, Loss: 2.0747\n",
      "Learning rate: 0.005, Iteration number: 233000/300000, Loss: 1.9782\n",
      "Learning rate: 0.005, Iteration number: 234000/300000, Loss: 1.8224\n",
      "Learning rate: 0.005, Iteration number: 235000/300000, Loss: 2.0825\n",
      "Learning rate: 0.005, Iteration number: 236000/300000, Loss: 1.9177\n",
      "Learning rate: 0.005, Iteration number: 237000/300000, Loss: 1.9828\n",
      "Learning rate: 0.005, Iteration number: 238000/300000, Loss: 1.8080\n",
      "Learning rate: 0.005, Iteration number: 239000/300000, Loss: 1.9795\n",
      "Learning rate: 0.005, Iteration number: 240000/300000, Loss: 1.9600\n",
      "Learning rate: 0.005, Iteration number: 241000/300000, Loss: 1.8194\n",
      "Learning rate: 0.005, Iteration number: 242000/300000, Loss: 1.8652\n",
      "Learning rate: 0.005, Iteration number: 243000/300000, Loss: 2.0293\n",
      "Learning rate: 0.005, Iteration number: 244000/300000, Loss: 1.9874\n",
      "Learning rate: 0.005, Iteration number: 245000/300000, Loss: 2.0001\n",
      "Learning rate: 0.005, Iteration number: 246000/300000, Loss: 1.7931\n",
      "Learning rate: 0.005, Iteration number: 247000/300000, Loss: 1.9564\n",
      "Learning rate: 0.005, Iteration number: 248000/300000, Loss: 2.0969\n",
      "Learning rate: 0.005, Iteration number: 249000/300000, Loss: 1.9550\n",
      "Learning rate: 0.005, Iteration number: 250000/300000, Loss: 2.1224\n",
      "Learning rate: 0.005, Iteration number: 251000/300000, Loss: 1.8073\n",
      "Learning rate: 0.005, Iteration number: 252000/300000, Loss: 2.1712\n",
      "Learning rate: 0.005, Iteration number: 253000/300000, Loss: 2.0626\n",
      "Learning rate: 0.005, Iteration number: 254000/300000, Loss: 1.9780\n",
      "Learning rate: 0.005, Iteration number: 255000/300000, Loss: 2.1009\n",
      "Learning rate: 0.005, Iteration number: 256000/300000, Loss: 1.9440\n",
      "Learning rate: 0.005, Iteration number: 257000/300000, Loss: 2.0727\n",
      "Learning rate: 0.005, Iteration number: 258000/300000, Loss: 1.9935\n",
      "Learning rate: 0.005, Iteration number: 259000/300000, Loss: 2.0113\n",
      "Learning rate: 0.005, Iteration number: 260000/300000, Loss: 1.9434\n",
      "Learning rate: 0.005, Iteration number: 261000/300000, Loss: 1.8209\n",
      "Learning rate: 0.005, Iteration number: 262000/300000, Loss: 1.9945\n",
      "Learning rate: 0.005, Iteration number: 263000/300000, Loss: 1.8456\n",
      "Learning rate: 0.005, Iteration number: 264000/300000, Loss: 1.8625\n",
      "Learning rate: 0.005, Iteration number: 265000/300000, Loss: 1.7470\n",
      "Learning rate: 0.005, Iteration number: 266000/300000, Loss: 1.9794\n",
      "Learning rate: 0.005, Iteration number: 267000/300000, Loss: 2.0634\n",
      "Learning rate: 0.005, Iteration number: 268000/300000, Loss: 1.8419\n",
      "Learning rate: 0.005, Iteration number: 269000/300000, Loss: 1.9512\n",
      "Learning rate: 0.005, Iteration number: 270000/300000, Loss: 2.0097\n",
      "Learning rate: 0.005, Iteration number: 271000/300000, Loss: 2.0684\n",
      "Learning rate: 0.005, Iteration number: 272000/300000, Loss: 1.9219\n",
      "Learning rate: 0.005, Iteration number: 273000/300000, Loss: 1.9377\n",
      "Learning rate: 0.005, Iteration number: 274000/300000, Loss: 2.0603\n",
      "Learning rate: 0.005, Iteration number: 275000/300000, Loss: 1.9451\n",
      "Learning rate: 0.005, Iteration number: 276000/300000, Loss: 1.9616\n",
      "Learning rate: 0.005, Iteration number: 277000/300000, Loss: 1.9923\n",
      "Learning rate: 0.005, Iteration number: 278000/300000, Loss: 1.9538\n",
      "Learning rate: 0.005, Iteration number: 279000/300000, Loss: 2.1528\n",
      "Learning rate: 0.005, Iteration number: 280000/300000, Loss: 2.1275\n",
      "Learning rate: 0.005, Iteration number: 281000/300000, Loss: 1.9978\n",
      "Learning rate: 0.005, Iteration number: 282000/300000, Loss: 2.0646\n",
      "Learning rate: 0.005, Iteration number: 283000/300000, Loss: 1.7636\n",
      "Learning rate: 0.005, Iteration number: 284000/300000, Loss: 2.0814\n",
      "Learning rate: 0.005, Iteration number: 285000/300000, Loss: 2.1285\n",
      "Learning rate: 0.005, Iteration number: 286000/300000, Loss: 1.8195\n",
      "Learning rate: 0.005, Iteration number: 287000/300000, Loss: 2.0467\n",
      "Learning rate: 0.005, Iteration number: 288000/300000, Loss: 2.0600\n",
      "Learning rate: 0.005, Iteration number: 289000/300000, Loss: 1.8710\n",
      "Learning rate: 0.005, Iteration number: 290000/300000, Loss: 2.0197\n",
      "Learning rate: 0.005, Iteration number: 291000/300000, Loss: 1.9957\n",
      "Learning rate: 0.005, Iteration number: 292000/300000, Loss: 2.0612\n",
      "Learning rate: 0.005, Iteration number: 293000/300000, Loss: 1.8784\n",
      "Learning rate: 0.005, Iteration number: 294000/300000, Loss: 2.0110\n",
      "Learning rate: 0.005, Iteration number: 295000/300000, Loss: 2.0048\n",
      "Learning rate: 0.005, Iteration number: 296000/300000, Loss: 1.9136\n",
      "Learning rate: 0.005, Iteration number: 297000/300000, Loss: 1.9443\n",
      "Learning rate: 0.005, Iteration number: 298000/300000, Loss: 1.8828\n",
      "Learning rate: 0.005, Iteration number: 299000/300000, Loss: 2.0871\n",
      "Learning rate: 0.005, Iteration number: 299999/300000, Loss: 2.1171\n"
     ]
    }
   ],
   "source": [
    "# define lr and iterations arrays\n",
    "lr = [0.1, 0.01, 0.005]\n",
    "iterations = [100000, 100000, 100000]\n",
    "total_iterations = 0 # keep track of total iterations\n",
    "batch_size = 128\n",
    "lossi = [] # keep track of loss\n",
    "\n",
    "# loop through pairs of lr and iterations\n",
    "for lr, it in zip(lr, iterations):\n",
    "    for i in range(it):\n",
    "        \n",
    "        # minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "        \n",
    "        # forward pass\n",
    "        emb = layers[0](Xb) # embed the characters into vectors\n",
    "        embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "        x = model(Xb)\n",
    "        x = x + skip_layer(embcat)\n",
    "        loss = F.cross_entropy(x, Yb)\n",
    "\n",
    "\n",
    "        # backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        for p in parameters:\n",
    "            p.data += -lr * p.grad\n",
    "\n",
    "        # track stats\n",
    "        if i % 1000 == 0 or i == it - 1:\n",
    "            print(f'Learning rate: {lr}, Iteration number: {total_iterations}/{sum(iterations)}, Loss: {loss.item():.4f}')\n",
    "        lossi.append(loss.log10().item())\n",
    "        total_iterations += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15d7db390>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lossi = torch.tensor(lossi)\n",
    "#lossi = lossi.view((-1, 1000)).mean(dim=1)\n",
    "plt.plot(torch.tensor(lossi).view((-1, 1000)).mean(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.96418035030365\n",
      "val 2.0578064918518066\n"
     ]
    }
   ],
   "source": [
    "# evaluate the loss\n",
    "@torch.no_grad()  # this decorator disables gradient tracking inside pytorch\n",
    "def split_loss(split):\n",
    "    x, y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte),\n",
    "    }[split]\n",
    "    emb = layers[0](x)\n",
    "    x = model(x)\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    x += skip_layer(embcat)\n",
    "    loss = F.cross_entropy(x, y)\n",
    "    \n",
    "\n",
    "    print(split, loss.item())\n",
    "\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palili\n",
      "jadison\n",
      "zlen\n",
      "leighan\n",
      "knaidi\n",
      "writtom\n",
      "ahrina\n",
      "kauva\n",
      "nadhi\n",
      "ivanne\n",
      "gemiels\n",
      "diom\n",
      "teriergen\n",
      "shrustin\n",
      "aadira\n",
      "knellemi\n"
     ]
    }
   ],
   "source": [
    "def sample(num_samples=20):\n",
    "    samples = []\n",
    "    for i in range(num_samples):\n",
    "        out = []\n",
    "        context = [0] * block_size\n",
    "        while True:\n",
    "            x = torch.tensor(context[-block_size:]).unsqueeze(0)\n",
    "            emb = layers[0](x)\n",
    "\n",
    "            x = model(x)\n",
    "            embcat = emb.view(emb.shape[0], -1)\n",
    "            x += skip_layer(embcat)\n",
    "            x = x.squeeze()\n",
    "            x = F.softmax(x, dim=-1)\n",
    "            x = torch.multinomial(x, 1).item()\n",
    "            if x == 0:\n",
    "                break\n",
    "            out.append(itos[x])\n",
    "            context = context[1:] + [x]\n",
    "        samples.append(''.join(out))\n",
    "    return samples\n",
    "\n",
    "sample = sample()\n",
    "for s in sample:\n",
    "    if s not in words:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
